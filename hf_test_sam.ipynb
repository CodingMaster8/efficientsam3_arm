{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "afa06e7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Using Apple Metal GPU (MPS)\n",
      "üìÇ Loading SAM 3 Image Model from: './sam3_model'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading weights: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1468/1468 [00:01<00:00, 1430.22it/s, Materializing param=vision_encoder.neck.fpn_layers.3.proj2.weight]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Model loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from transformers import Sam3Model, Sam3Processor\n",
    "from PIL import Image\n",
    "import requests\n",
    "\n",
    "# 1. Setup Device\n",
    "if torch.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "    print(\"‚úÖ Using Apple Metal GPU (MPS)\")\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "    print(\"‚ö†Ô∏è MPS not available. Using CPU\")\n",
    "\n",
    "# 2. Load Model from LOCAL FOLDER\n",
    "local_path = \"./sam3_model\"\n",
    "print(f\"üìÇ Loading SAM 3 Image Model from: '{local_path}'...\")\n",
    "\n",
    "try:\n",
    "    processor = Sam3Processor.from_pretrained(local_path, trust_remote_code=True)\n",
    "    model = Sam3Model.from_pretrained(local_path, trust_remote_code=True).to(device)\n",
    "    print(\"‚úÖ Model loaded successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå LOAD ERROR: {e}\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "54b09e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fb5620cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_image(image_path, prompt, model, processor, device=\"mps\"):\n",
    "    \"\"\"\n",
    "    Segments objects in an image based on a text prompt.\n",
    "    \n",
    "    Args:\n",
    "        image_path (str): Path to the local image file.\n",
    "        prompt (str): Text prompt (e.g., \"cat\").\n",
    "        model: The loaded Sam3Model.\n",
    "        processor: The loaded Sam3Processor.\n",
    "        device (str): \"mps\" for Mac or \"cpu\".\n",
    "\n",
    "    Returns:\n",
    "        PIL.Image: The original image with a red overlay on detected objects.\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Load & Verify Image\n",
    "    try:\n",
    "        raw_image = Image.open(image_path).convert(\"RGB\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error opening image: {e}\")\n",
    "        return None\n",
    "\n",
    "    # 2. Process Inputs (Manual Split for Stability)\n",
    "    # A. Image\n",
    "    image_inputs = processor.image_processor(\n",
    "        raw_image, \n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    \n",
    "    # B. Text (Strict max_length=32 for SAM 3)\n",
    "    text_inputs = processor.tokenizer(\n",
    "        [prompt], \n",
    "        return_tensors=\"pt\",\n",
    "        padding=\"max_length\",\n",
    "        max_length=32,\n",
    "        truncation=True\n",
    "    )\n",
    "    \n",
    "    # C. Combine & Move to GPU\n",
    "    inputs = dict(image_inputs)\n",
    "    inputs.update(text_inputs)\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    \n",
    "    # 3. Run Inference\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        \n",
    "    # 4. Post-Process results\n",
    "    # Convert tensor size to list to avoid TypeError\n",
    "    target_sizes = image_inputs[\"original_sizes\"].tolist()\n",
    "    \n",
    "    results = processor.post_process_instance_segmentation(\n",
    "        outputs, \n",
    "        threshold=0.5, \n",
    "        mask_threshold=0.5, \n",
    "        target_sizes=target_sizes\n",
    "    )[0]\n",
    "    \n",
    "    # 5. Create Visualization\n",
    "    if len(results['masks']) > 0:\n",
    "        # Combine ALL found masks into one layer (in case there are 2 cats)\n",
    "        all_masks_np = results['masks'].cpu().numpy()\n",
    "        combined_mask = np.max(all_masks_np, axis=0) \n",
    "        \n",
    "        # Resize mask to match original image dimensions\n",
    "        mask_image = Image.fromarray((combined_mask * 255).astype('uint8')).resize(raw_image.size)\n",
    "        \n",
    "        # Create a transparent Red layer (R, G, B, Alpha)\n",
    "        red_layer = Image.new(\"RGBA\", raw_image.size, (255, 0, 0, 100)) \n",
    "        \n",
    "        # Paste the red layer using the mask as the transparency guide\n",
    "        final_image = raw_image.convert(\"RGBA\")\n",
    "        final_image.paste(red_layer, (0,0), mask_image)\n",
    "        \n",
    "        return final_image\n",
    "    else:\n",
    "        print(f\"ü§∑ No objects found for prompt: '{prompt}'\")\n",
    "        return raw_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "58290532",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_image = \"efficientsam3_arm/assets/persons.jpg\"  # Make sure this file exists\n",
    "my_prompt = \"person\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cc64210f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚öôÔ∏è  Preparing input for 'persons'...\n",
      "\n",
      "üöÄ Testing on MPS...\n",
      "   üî• Warming up...\n",
      "   ‚è±Ô∏è  Running 5 loops...\n",
      "      Run 1: 11.8456s\n",
      "      Run 2: 12.1344s\n",
      "      Run 3: 10.6460s\n",
      "      Run 4: 7.2120s\n",
      "      Run 5: 4.7849s\n",
      "   ‚úÖ MPS Average: 9.3246 seconds\n",
      "\n",
      "üöÄ Testing on CPU...\n",
      "   üî• Warming up...\n",
      "   ‚è±Ô∏è  Running 5 loops...\n",
      "      Run 1: 8.9002s\n",
      "      Run 2: 7.6865s\n",
      "      Run 3: 7.2332s\n",
      "      Run 4: 7.1389s\n",
      "      Run 5: 7.2409s\n",
      "   ‚úÖ CPU Average: 7.6399 seconds\n",
      "\n",
      "========================================\n",
      "üèÜ RESULT: MPS is 0.8x faster than CPU\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import torch\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "def benchmark_inference(image_path, prompt, model, processor, runs=5):\n",
    "    \"\"\"\n",
    "    Compares inference speed between MPS (GPU) and CPU.\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Prepare Data (Do this once)\n",
    "    print(f\"‚öôÔ∏è  Preparing input for '{prompt}'...\")\n",
    "    raw_image = Image.open(image_path).convert(\"RGB\")\n",
    "    \n",
    "    # Process inputs (CPU side)\n",
    "    image_inputs = processor.image_processor(raw_image, return_tensors=\"pt\")\n",
    "    text_inputs = processor.tokenizer(\n",
    "        [prompt], \n",
    "        return_tensors=\"pt\", \n",
    "        padding=\"max_length\", \n",
    "        max_length=32, \n",
    "        truncation=True\n",
    "    )\n",
    "    \n",
    "    # Combine inputs into a dictionary\n",
    "    base_inputs = dict(image_inputs)\n",
    "    base_inputs.update(text_inputs)\n",
    "\n",
    "    # --- Helper Function to Run Timing ---\n",
    "    def run_timing(device_name):\n",
    "        print(f\"\\nüöÄ Testing on {device_name.upper()}...\")\n",
    "        \n",
    "        # A. Move Model & Inputs to Device\n",
    "        device = torch.device(device_name)\n",
    "        model.to(device)\n",
    "        inputs = {k: v.to(device) for k, v in base_inputs.items()}\n",
    "        \n",
    "        # B. Warm-up (Important!)\n",
    "        # We run it once so PyTorch compiles the kernels. \n",
    "        # Without this, the first run looks much slower than reality.\n",
    "        print(\"   üî• Warming up...\")\n",
    "        with torch.no_grad():\n",
    "            _ = model(**inputs)\n",
    "            if device_name == \"mps\":\n",
    "                torch.mps.synchronize() # Wait for GPU to finish\n",
    "        \n",
    "        # C. Measure Loop\n",
    "        print(f\"   ‚è±Ô∏è  Running {runs} loops...\")\n",
    "        times = []\n",
    "        \n",
    "        for i in range(runs):\n",
    "            start = time.perf_counter()\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                _ = model(**inputs)\n",
    "                \n",
    "            # Crucial: GPU is async, we must wait for it to finish before stopping clock\n",
    "            if device_name == \"mps\":\n",
    "                torch.mps.synchronize()\n",
    "                \n",
    "            end = time.perf_counter()\n",
    "            times.append(end - start)\n",
    "            print(f\"      Run {i+1}: {end - start:.4f}s\")\n",
    "            \n",
    "        avg_time = sum(times) / len(times)\n",
    "        print(f\"   ‚úÖ {device_name.upper()} Average: {avg_time:.4f} seconds\")\n",
    "        return avg_time\n",
    "\n",
    "    # 2. Run MPS Test\n",
    "    mps_time = run_timing(\"mps\")\n",
    "    \n",
    "    # 3. Run CPU Test\n",
    "    cpu_time = run_timing(\"cpu\")\n",
    "    \n",
    "    # 4. Compare\n",
    "    speedup = cpu_time / mps_time\n",
    "    print(\"\\n\" + \"=\"*40)\n",
    "    print(f\"üèÜ RESULT: MPS is {speedup:.1f}x faster than CPU\")\n",
    "    print(\"=\"*40)\n",
    "\n",
    "# --- EXECUTE ---\n",
    "# Replace with your actual image path\n",
    "benchmark_inference(my_image, \"persons\", model, processor, runs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d4092940",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚öôÔ∏è  Preparing input for 'persons'...\n",
      "\n",
      "üöÄ Testing on MPS...\n",
      "   üî• Warming up (5 loops - ignored)...\n",
      "   ‚è±Ô∏è  Running 10 loops (measuring)...\n",
      "   ‚úÖ MPS Average: 4.9935s | Best: 4.7233s\n",
      "\n",
      "üöÄ Testing on CPU...\n",
      "   üî• Warming up (5 loops - ignored)...\n",
      "   ‚è±Ô∏è  Running 10 loops (measuring)...\n",
      "   ‚úÖ CPU Average: 7.7520s | Best: 7.1564s\n",
      "\n",
      "========================================\n",
      "üèÜ STEADY STATE RESULT: MPS is 1.6x faster\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import torch\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "def benchmark_inference_fixed(image_path, prompt, model, processor, warmups=3, test_runs=10):\n",
    "    \n",
    "    # 1. Prepare Data\n",
    "    print(f\"‚öôÔ∏è  Preparing input for '{prompt}'...\")\n",
    "    raw_image = Image.open(image_path).convert(\"RGB\")\n",
    "    \n",
    "    image_inputs = processor.image_processor(raw_image, return_tensors=\"pt\")\n",
    "    text_inputs = processor.tokenizer(\n",
    "        [prompt], \n",
    "        return_tensors=\"pt\", \n",
    "        padding=\"max_length\", \n",
    "        max_length=32, \n",
    "        truncation=True\n",
    "    )\n",
    "    \n",
    "    base_inputs = dict(image_inputs)\n",
    "    base_inputs.update(text_inputs)\n",
    "\n",
    "    def run_timing(device_name):\n",
    "        print(f\"\\nüöÄ Testing on {device_name.upper()}...\")\n",
    "        device = torch.device(device_name)\n",
    "        model.to(device)\n",
    "        inputs = {k: v.to(device) for k, v in base_inputs.items()}\n",
    "        \n",
    "        # --- AGGRESSIVE WARMUP ---\n",
    "        # We run multiple times specifically to trigger the JIT compilation on Mac\n",
    "        print(f\"   üî• Warming up ({warmups} loops - ignored)...\")\n",
    "        for _ in range(warmups):\n",
    "            with torch.no_grad():\n",
    "                _ = model(**inputs)\n",
    "                if device_name == \"mps\":\n",
    "                    torch.mps.synchronize()\n",
    "        \n",
    "        # --- REAL TEST ---\n",
    "        print(f\"   ‚è±Ô∏è  Running {test_runs} loops (measuring)...\")\n",
    "        times = []\n",
    "        \n",
    "        for i in range(test_runs):\n",
    "            start = time.perf_counter()\n",
    "            with torch.no_grad():\n",
    "                _ = model(**inputs)\n",
    "            \n",
    "            if device_name == \"mps\":\n",
    "                torch.mps.synchronize()\n",
    "                \n",
    "            end = time.perf_counter()\n",
    "            times.append(end - start)\n",
    "            # Optional: Print every run to ensure it's stable\n",
    "            # print(f\"      Run {i+1}: {end - start:.4f}s\")\n",
    "            \n",
    "        avg_time = sum(times) / len(times)\n",
    "        best_time = min(times)\n",
    "        \n",
    "        print(f\"   ‚úÖ {device_name.upper()} Average: {avg_time:.4f}s | Best: {best_time:.4f}s\")\n",
    "        return avg_time\n",
    "\n",
    "    # Run Benchmark\n",
    "    mps_time = run_timing(\"mps\")\n",
    "    cpu_time = run_timing(\"cpu\")\n",
    "    \n",
    "    speedup = cpu_time / mps_time\n",
    "    print(\"\\n\" + \"=\"*40)\n",
    "    print(f\"üèÜ STEADY STATE RESULT: MPS is {speedup:.1f}x faster\")\n",
    "    print(\"=\"*40)\n",
    "\n",
    "# Run with more loops to see the real stability\n",
    "benchmark_inference_fixed(my_image, \"persons\", model, processor, warmups=5, test_runs=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
